<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Vinicius Prado da Fonseca | publications</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/css/mdb.min.css" integrity="sha256-/SwJ2GDcEt5382i8zqDwl36VJGECxEoIcBIuoLmLR4g=" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"  integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/~vpradodafons/assets/img/favicon.ico">
<link rel="stylesheet" href="/~vpradodafons/assets/css/main.css">

<link rel="canonical" href="/~vpradodafons/publications/">

<!-- Open Graph -->


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
      
      
      
      <a class="navbar-brand title font-weight-lighter" href="https://www.cs.mun.ca/~vpradodafons/">
       <span class="font-weight-bold">Vinicius</span>   Prado da Fonseca
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/~vpradodafons/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/~vpradodafons/collaborations/">
                collaborations
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/~vpradodafons/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/~vpradodafons/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/~vpradodafons/supervisions/">
                supervisions
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/~vpradodafons/teaching/">
                teaching
                
              </a>
          </li>
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">Recent publications.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Haranwala2022" class="col-sm-8">
    
      <span class="title">A Dashboard Tool for Mobility Data Mining Preprocessing Tasks</span>
      <span class="author">
        
          
            
              
                
                  Haranwala, Yaksh J.,
                
              
            
          
        
          
            
              
                
                  Haidri, Salman,
                
              
            
          
        
          
            
              
                
                  Tricco, Terrence S.,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius P.</a>,
                
              
            
          
        
          
            
              
                
                  and Soares, Amilcar
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2022 23rd IEEE International Conference on Mobile Data Management (MDM)</em>
      
      
        2022
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Mobility data mining has received significant interest in the literature in the last few years since social media, sensor networks, IoT, and GPS devices generate a vast amount of data. Its growth was also boosted by the growing availability of machine learning algorithms and Python libraries for trajectory analysis. However, we believe that a proper tool that supports trajectory data preprocessing tasks using a dashboard-like application is missing. Such a tool helps users visualize the effects of preprocessing techniques and adequately select the ones that have a desired effect on the data. This demo proposes a tool that combines state-of-the-art Python trajectory analysis libraries to preprocess trajectory data and visualize their effect using a dashboard with maps, tables, and charts that will assist the user through this challenging process.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Oliveira2022" class="col-sm-8">
    
      <span class="title">BioIn-Tacto: tactile sensing module design files and source code.</span>
      <span class="author">
        
          
            
              
                
                  Oliveira, Thiago Eustaquio Alves,
                
              
            
          
        
          
            
              
                
                  and <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado</a>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em></em>
      
      
        2022
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Wang2022" class="col-sm-8">
    
      <span class="title">Integrating computer vision to prosthetic hand control with sEMG: Preliminary results in grasp classification</span>
      <span class="author">
        
          
            
              
                
                  Wang, Shuo,
                
              
            
          
        
          
            
              
                
                  Zheng, Jingjing,
                
              
            
          
        
          
            
              
                
                  Huang, Ziwei,
                
              
            
          
        
          
            
              
                
                  Zhang, Xiaoqin,
                
              
            
          
        
          
            
              
                <em>Prado da Fonseca, Vinicius</em>,
              
            
          
        
          
            
              
                
                  Zheng, Bin,
                
              
            
          
        
          
            
              
                
                  and Jiang, Xianta
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>Frontiers in Robotics and AI</em>
      
      
        2022
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>The myoelectric prosthesis is a promising tool to restore the hand abilities of amputees, but the classification accuracy of surface electromyography (sEMG) is not high enough for real-time application. Researchers proposed integrating sEMG signals with another feature that is not affected by amputation. The strong coordination between vision and hand manipulation makes us consider including visual information in prosthetic hand control. In this study, we identified a sweet period during the early reaching phase in which the vision data could yield a higher accuracy in classifying the grasp patterns. Moreover, the visual classification results from the sweet period could be naturally integrated with sEMG data collected during the grasp phase. After the integration, the accuracy of grasp classification increased from 85.5% (only sEMG) to 90.06% (integrated). Knowledge gained from this study encourages us to further explore the methods for incorporating computer vision into myoelectric data to enhance the movement control of prosthetic hands.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Haidri2022" class="col-sm-8">
    
      <span class="title">PTRAIL — A python package for parallel trajectory data preprocessing</span>
      <span class="author">
        
          
            
              
                
                  Haidri, Salman,
                
              
            
          
        
          
            
              
                
                  Haranwala, Yaksh J.,
                
              
            
          
        
          
            
              
                
                  Bogorny, Vania,
                
              
            
          
        
          
            
              
                
                  Renso, Chiara,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado</a>,
                
              
            
          
        
          
            
              
                
                  and Soares, Amilcar
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>SoftwareX</em>
      
      
        2022
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="DaFonseca2022" class="col-sm-8">
    
      <span class="title">Tactile object recognition in early phases of grasping using underactuated robotic hands</span>
      <span class="author">
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado</a>,
                
              
            
          
        
          
            
              
                
                  Jiang, Xianta,
                
              
            
          
        
          
            
              
                
                  Petriu, Emil M,
                
              
            
          
        
          
            
              
                
                  and Oliveira, Thiago Eustaquio Alves
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>Intelligent Service Robotics</em>
      
      
        2022
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Carvalho2022" class="col-sm-8">
    
      <span class="title">Evaluating Data Representations for Object Recognition During Pick-and-Place Manipulation Tasks</span>
      <span class="author">
        
          
            
              
                
                  Carvalho, Humberto Navarro De,
                
              
            
          
        
          
            
              
                
                  Castro, Lucas Pontes,
                
              
            
          
        
          
            
              
                
                  Rego, Thais G. Do,
                
              
            
          
        
          
            
              
                
                  Filho, Telmo M. Silva,
                
              
            
          
        
          
            
              
                
                  Barbosa, Yuri de A. M.,
                
              
            
          
        
          
            
              
                
                  Batista, Leonardo Vidal,
                
              
            
          
        
          
            
              
                
                  Soares, Amilcar,
                
              
            
          
        
          
            
              
                
                  and <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado Da</a>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2022 IEEE International Systems Conference (SysCon)</em>
      
      
        2022
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Welyhorsky2022" class="col-sm-8">
    
      <span class="title">Neuro-Fuzzy Grasp Control for a Teleoperated Five Finger Anthropomorphic Robotic Hand</span>
      <span class="author">
        
          
            
              
                
                  Welyhorsky, Maxwell,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Prado Da Fonseca, Vinicius</a>,
                
              
            
          
        
          
            
              
                
                  Zhu, Qi,
                
              
            
          
        
          
            
              
                
                  Rocha Lima, Bruno Monteiro,
                
              
            
          
        
          
            
              
                
                  Alves De Oliveira, Thiago Eustaquio,
                
              
            
          
        
          
            
              
                
                  and Petriu, Emil M
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2022 IEEE International Systems Conference (SysCon)</em>
      
      
        2022
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="RochaLima2021" class="col-sm-8">
    
      <span class="title">Classification of Textures using a Tactile-Enabled Finger in Dynamic Exploration Tasks</span>
      <span class="author">
        
          
            
              
                
                  Rocha Lima, Bruno Monteiro,
                
              
            
          
        
          
            
              
                
                  Alves de Oliveira, Thiago Eustaquio,
                
              
            
          
        
          
            
              
                
                  and <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado</a>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2021 IEEE Sensors</em>
      
      
        2021
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Reproducing human-like dexterous manipulation in robots requires identifying objects and ures. In unstructured settings, robots equipped with tactile sensors can detect ures by using touch-related characteristics. The use of a tactile-enabled finger for ure categorization is investigated in this article. Four machine learning methods are used to recognize ures from the data of pressure, gravity, angular rate, magnetic field sensors embedded in the compliant structure of a multimodal tactile sensing module. Machine learning models trained on data retrieved during 2-dimensional exploration of sample ures achieved classification accuracy rates of more than 90% for all features.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Boente2021" class="col-sm-8">
    
      <span class="title">Small Scale Unmanned Aircraft System and Photogrammetry Applied for 3D Modeling of Historical Buildings</span>
      <span class="author">
        
          
            
              
                
                  Boente, Alexandre,
                
              
            
          
        
          
            
              
                
                  Baldivieso, Thiago,
                
              
            
          
        
          
            
              
                
                  Oliveira, Thiago,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius</a>,
                
              
            
          
        
          
            
              
                
                  and Rosa, Paulo
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In SENSORDEVICES 2021, The Twelfth International Conference on Sensor Device Technologies and Applications</em>
      
      
        2021
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="PradodaFonseca2021" class="col-sm-8">
    
      <span class="title">Tactile Sensor Analysis during Early Stages of Manipulation for Single Grasp Identification of Daily Objects</span>
      <span class="author">
        
          
            
              <em>Prado da Fonseca, Vinicius</em>
            
          
        
      </span>

      <span class="periodical">
      
        <em>Engineering Proceedings</em>
      
      
        2021
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Dexterous robotic manipulation in unstructured environments is still challenging, despite the increasing number of robots entering human settings each day. Even though robotic manipulation provides complete solutions in factories and industries, it still lacks essential techniques, displaying clumsy or limited operation in unstructured environments. Daily objects typically aim at the human hand, and the human somatosensory system is responsible for solving all the complex calculations required for dexterous manipulations in unstructured settings. Borrowing concepts of the human visuotactile system can improve dexterous manipulation and increase robotics usage in unstructured environments. In humans, required finger and wrist joint adjustments occur after fast identification of the object in the initial stages of manipulation. Fast object identification during those phases may increase robotic dexterous manipulation performance. The present paper explores human-inspired concepts such as haptic glance to develop robotic single-grasp object identification. This concept can assist early phases of robotic manipulation, helping automated decision-making, such as type of grasp and joint position, during manipulation tasks. The main stages developed here are detecting sensor activation and sample collection using signal-to-noise and z-score filtering on tactile data. This procedure automates touch detection and reduces the sensor space for classification. Experiments on a daily objects dataset presented compelling results that will assist in the later stages of the early phases of robotic grasping.</p>
    </span>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Pirozzi2020" class="col-sm-8">
    
      <span class="title">Tactile Sensors for Robotic Applications</span>
      <span class="author">
        
          
            
              Pirozzi, Salvatore
            
          
        
      </span>

      <span class="periodical">
      
        <em>Sensors</em>
      
      
        2020
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>In recent years, tactile sensing has become a key enabling technology to implement complex tasks by using robotic systems [...]</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Monteiro2020" class="col-sm-8">
    
      <span class="title">Dynamic Tactile Exploration for Texture Classification using a Miniaturized Multi-modal Tactile Sensor and Machine Learning</span>
      <span class="author">
        
          
            
              
                
                  Lima, Bruno Monteiro Rocha,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado</a>,
                
              
            
          
        
          
            
              
                
                  Oliveira, Thiago Eustaquio Alves,
                
              
            
          
        
          
            
              
                
                  Zhu, Qi,
                
              
            
          
        
          
            
              
                
                  and Petriu, Emil M.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2020 IEEE International Systems Conference (SysCon)</em>
      
      
        2020
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Zhu2020" class="col-sm-8">
    
      <span class="title">Teleoperated Grasping Using a Robotic Hand and a Haptic-Feedback Data Glove</span>
      <span class="author">
        
          
            
              
                
                  Zhu, Qi,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado</a>,
                
              
            
          
        
          
            
              
                
                  Lima, Bruno Monteiro Rocha,
                
              
            
          
        
          
            
              
                
                  Welyhorsky, Maxwell,
                
              
            
          
        
          
            
              
                
                  Goubran, Miriam,
                
              
            
          
        
          
            
              
                
                  Oliveira, Thiago Eustaquio Alves,
                
              
            
          
        
          
            
              
                
                  and Petriu, Emil M
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2020 IEEE International Systems Conference (SysCon)</em>
      
      
        2020
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="RochaLima2019" class="col-sm-8">
    
      <span class="title">Heart Rate Detection Using a Miniaturized Multimodal Tactile Sensor</span>
      <span class="author">
        
          
            
              
                
                  Rocha Lima, Bruno Monteiro,
                
              
            
          
        
          
            
              
                
                  Eustaquio Alves de Oliveira, Thiago,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado</a>,
                
              
            
          
        
          
            
              
                
                  Zhu, Qi,
                
              
            
          
        
          
            
              
                
                  Goubran, Miriam,
                
              
            
          
        
          
            
              
                
                  Groza, Voicu Z.,
                
              
            
          
        
          
            
              
                
                  and Petriu, Emil M.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2019 IEEE International Symposium on Medical Measurements and Applications (MeMeA)</em>
      
      
        2019
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="AlvesdeOliveira2019" class="col-sm-8">
    
      <span class="title">End-Effector Approach Flexibilization in a Surface Approximation Task Using a Bioinspired Tactile Sensing Module</span>
      <span class="author">
        
          
            
              
                
                  Alves de Oliveira, Thiago Eustaquio,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado</a>,
                
              
            
          
        
          
            
              
                
                  Lima, Bruno Monteiro Rocha,
                
              
            
          
        
          
            
              
                
                  Cretu, Ana-Maria,
                
              
            
          
        
          
            
              
                
                  and Petriu, M.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2019 IEEE International Symposium on Robotic and Sensors Environments (ROSE)</em>
      
      
        2019
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>The flexibilization of the end-effector orientation constraint is critical in various robotic tasks, in particular when approaching surfaces of unknown objects and when unexpected contacts occur. This paper presents the use of a bioinspired multimodal tactile sensing module for tasks requiring knowledge about the inclination of a surface. The advantage of this module is that it can detect the pitch of the surface even though the pitch of the end-effector that carries the module during exploration is kept constant. Such flexibilization is achieved due to the compliant nature of the sensing module, its inner organization and the placement of embedded sensors.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="DaFonseca2019-MeMeA" class="col-sm-8">
    
      <span class="title">In-Hand Telemanipulation Using a Robotic Hand and Biology-Inspired Haptic Sensing</span>
      <span class="author">
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado</a>,
                
              
            
          
        
          
            
              
                
                  Monteiro Rocha Lima, Bruno,
                
              
            
          
        
          
            
              
                
                  Alves de Oliveira, Thiago Eustaquio,
                
              
            
          
        
          
            
              
                
                  Zhu, Qi,
                
              
            
          
        
          
            
              
                
                  Groza, Voicu Z.,
                
              
            
          
        
          
            
              
                
                  and Petriu, Emil M.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2019 IEEE International Symposium on Medical Measurements and Applications (MeMeA)</em>
      
      
        2019
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>"Part Number: CFP19MEA-ART" "IEEE Catalog Number: CFP19MEA-USB"–PDF copyright page</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="PradodaFonseca2019" class="col-sm-8">
    
      <span class="title">Estimating the Orientation of Objects from Tactile Sensing Data Using Machine Learning Methods and Visual Frames of Reference</span>
      <span class="author">
        
          
            
              
                <em>Prado da Fonseca, Vinicius</em>,
              
            
          
        
          
            
              
                
                  Alves de Oliveira, Thiago Eustaquio,
                
              
            
          
        
          
            
              
                
                  and Petriu, Emil M.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>Sensors</em>
      
      
        2019
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Underactuated hands are useful tools for robotic in-hand manipulation tasks due to their capability to seamlessly adapt to unknown objects. To enable robots using such hands to achieve and maintain stable grasping conditions even under external disturbances while keeping track of an in-hand object’s state requires learning object-tactile sensing data relationships. The human somatosensory system combines visual and tactile sensing information in their “What and Where” subsystem to achieve high levels of manipulation skills. The present paper proposes an approach for estimating the pose of in-hand objects combining tactile sensing data and visual frames of reference like the human “What and Where” subsystem. The system proposed here uses machine learning methods to estimate the orientation of in-hand objects from the data gathered by tactile sensors mounted on the phalanges of underactuated fingers. While tactile sensing provides local information about objects during in-hand manipulation, a vision system generates egocentric and allocentric frames of reference. A dual fuzzy logic controller was developed to achieve and sustain stable grasping conditions autonomously while forces were applied to in-hand objects to expose the system to different object configurations. Two sets of experiments were used to explore the system capabilities. On the first set, external forces changed the orientation of objects while the fuzzy controller kept objects in-hand for tactile and visual data collection for five machine learning estimators. Among these estimators, the ridge regressor achieved an average mean squared error of 0.077 ∘ . On the second set of experiments, one of the underactuated fingers performed open-loop object rotations and data recorded were supplied to the same set of estimators. In this scenario, the Multilayer perceptron (MLP) neural network achieved the lowest mean squared error of 0.067 ∘ .</p>
    </span>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Zhi2018" class="col-sm-8">
    
      <span class="title">Teaching a robot sign language using vision-based hand gesture recognition</span>
      <span class="author">
        
          
            
              
                
                  Zhi, Da,
                
              
            
          
        
          
            
              
                
                  De Oliveira, Thiago E.Alves,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Da Fonseca, Vinicius Prado</a>,
                
              
            
          
        
          
            
              
                
                  and Petriu, Emil M.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>CIVEMSA 2018 - 2018 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications, Proceedings</em>
      
      
        2018
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>This paper presents a novel vision-based hand gesture recognition (HGR) and training system for a human-like robot hand. We implemented and trained a multiclass-SVM classifier and N-Dimensional DTW (ND-DTW) classifier for static posture recognition and dynamic gesture recognition. Training features were extracted from the raw gestures depth data captured by Leap Motion Controller. The experimental results show that multiclass SVM method has an average 98.25% recognition rates and the shortest run time when compared to k-NN and ANBC. For dynamic gestures, ND-DTW classifier displays a better performance than DHMM with an average 95.5% recognition rate and significantly shorter run time. In conclusion, the combination of SVMs and DTW proves the efficiency and high accuracy in proposed human-robot interaction system.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Kucherhan2018" class="col-sm-8">
    
      <span class="title">Object Recognition Through Manipulation Using Tactile Enabled Prosthetic Fingers and Feedback Glove - Experimental Study</span>
      <span class="author">
        
          
            
              
                
                  Kucherhan, Daniel J.,
                
              
            
          
        
          
            
              
                
                  Goubran, Miriam,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Da Fonseca, Vinicius P.</a>,
                
              
            
          
        
          
            
              
                
                  Alves De Oliveira, Thiago E.,
                
              
            
          
        
          
            
              
                
                  Petriu, Emil M.,
                
              
            
          
        
          
            
              
                
                  and Groza, Voicu
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>MeMeA 2018 - 2018 IEEE International Symposium on Medical Measurements and Applications, Proceedings</em>
      
      
        2018
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Kucherhan2019" class="col-sm-8">
    
      <span class="title">Object Recognition Through Manipulation Using Tactile Enabled Prosthetic Fingers and Feedback Glove - Experimental Study</span>
      <span class="author">
        
          
            
              
                
                  Kucherhan, Daniel J.,
                
              
            
          
        
          
            
              
                
                  Goubran, Miriam,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Da Fonseca, Vinicius P.</a>,
                
              
            
          
        
          
            
              
                
                  Alves De Oliveira, Thiago E.,
                
              
            
          
        
          
            
              
                
                  Petriu, Emil M.,
                
              
            
          
        
          
            
              
                
                  and Groza, Voicu
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>MeMeA 2018 - 2018 IEEE International Symposium on Medical Measurements and Applications, Proceedings</em>
      
      
        2018
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="DaFonseca2017-nao" class="col-sm-8">
    
      <span class="title">Fuzzy controlled object manipulation using a three-fingered robotic hand</span>
      <span class="author">
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado</a>,
                
              
            
          
        
          
            
              
                
                  Kucherhan, Daniel John,
                
              
            
          
        
          
            
              
                
                  Oliveira, Thiago E. Alves,
                
              
            
          
        
          
            
              
                
                  Zhi, Da,
                
              
            
          
        
          
            
              
                
                  and Petriu, Emil M.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2017 Annual IEEE International Systems Conference (SysCon)</em>
      
      
        2017
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>\textcopyright 2017 IEEE. Use of underactuated fingers to conduct precision, in-hand manipulation is a common topic of recent robotics research, mostly due to their relatively light weight and simplicity of use. Grasping operations are facilitated by compliant joints however precise, in-hand manipulation is more challenging since post-grasp orientation of an object varies. Underactuated, robotic-fingered hands that are capable of predictable grasping are one step closer to human-like end-effectors. This paper presents a new effort towards effective robotic manipulation using two underactuated fingers and one fully actuated robotic thumb with 3 degrees of freedom (DOF). Fuzzy grasping using tactile feedback is used to provide an enhanced stable grasp solution. The system comprises tactile feedback, orientation of underactuated phalanges using flexible joints, and thumb trajectory planning.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="PradoDaFonseca2017-IRIS" class="col-sm-8">
    
      <span class="title">Stable grasping and object reorientation with a three-fingered robotic hand</span>
      <span class="author">
        
          
            
              
                <em>Prado da Fonseca, Vinicius</em>,
              
            
          
        
          
            
              
                
                  Oliveira, Thiago E. Alves,
                
              
            
          
        
          
            
              
                
                  Eyre, Katerina,
                
              
            
          
        
          
            
              
                
                  and Petriu, Emil M.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2017 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS)</em>
      
      
        2017
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="PradodaFonseca2015" class="col-sm-8">
    
      <span class="title">Protocolo de comunicação para localização de objetos na casa inteligente</span>
      <span class="author">
        
          
            
              
                <em>Prado da Fonseca, Vinicius</em>,
              
            
          
        
          
            
              
                
                  and Rosa, Paulo Fernando Ferreira
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>Revista Militar de Ciência e Tecnologia</em>
      
      
        2015
      
      </span>
    

    <span class="links">
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="DeOliveira2015-mag" class="col-sm-8">
    
      <span class="title">Touch sensing for humanoid robots</span>
      <span class="author">
        
          
            
              
                
                  Oliveira, Thiago Eustaquio Alves,
                
              
            
          
        
          
            
              
                
                  Cretu, Ana-Maria,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.cs.mun.ca/~vpradodafons/publications/" target="_blank">Fonseca, Vinicius Prado</a>,
                
              
            
          
        
          
            
              
                
                  and Petriu, Emil M.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>IEEE Instrumentation &amp; Measurement Magazine</em>
      
      
        2015
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>A new generation of humanoid robots is emerging to work together with, or even replace, human operators performing complex dextrous manipulation operations in a variety of applications such as health and elder care, hazardous or high-risk environments, telemedicine, or manufacturing. To meet the challenging operational requirements of such applications, this new generation of humanoid robots should not only look as humans, but should also behave like them, being able to sense and perceive the external world and perform tasks as humans do. Touch sensing and perception is essential when handling objects while working on such complex activities in unstructured environments. The major challenges encountered when replicating the human touch sensing mechanisms are due to the inherently low resolution of the tactile images produced by the artificial sensors, to the complexity of interpreting the sensor data, and to the fact that robot hand technology is still clumsy when compared with the nimble dexterity of the human hand and fingers. This paper presents practical touch sensing solutions for humanoid robots (Fig. 1) that mimic the complex sensing mechanisms occurring in a human hand while exploring by touch 3D objects.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Cretu2015" class="col-sm-8">
    
      <span class="title">Computational intelligence and mechatronics solutions for robotic tactile object recognition</span>
      <span class="author">
        
          
            
              
                
                  Cretu, Ana-Maria,
                
              
            
          
        
          
            
              
                
                  Oliveira, Thiago Eustaquio Alves,
                
              
            
          
        
          
            
              
                <em>Prado da Fonseca, Vinicius</em>,
              
            
          
        
          
            
              
                
                  Tawbe, Bilal,
                
              
            
          
        
          
            
              
                
                  Petriu, Emil M.,
                
              
            
          
        
          
            
              
                
                  and Groza, Voicu Z.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2015 IEEE 9th International Symposium on Intelligent Signal Processing (WISP) Proceedings</em>
      
      
        2015
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>The paper discusses signal processing and mechatronics solutions for tactile object recognition using robotic hands. The two important aspects analyzed are the recognition of objects from tactile displacement profiles obtained by force sensing transducers and the recognition of textures using a rubbing motion executed by a robotic finger equipped with a dynamic tactile fingertip. Neural network solutions are used as an intelligent approach to recognize symbols, such as embossed numbers and letters, as well as for the recognition of different texture profiles. The conception issues, the challenges as well as the experimental results obtained are discussed from both a biological and a technological perspective.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="DeOliveira2015" class="col-sm-8">
    
      <span class="title">Data-driven analysis of kinaesthetic and tactile information for shape classification</span>
      <span class="author">
        
          
            
              
                
                  Eustaquio Alves de Oliveira, Thiago,
                
              
            
          
        
          
            
              
                <em>Prado da Fonseca, Vinicius</em>,
              
            
          
        
          
            
              
                
                  Huluta, Emanuil,
                
              
            
          
        
          
            
              
                
                  Rosa, Paulo F F,
                
              
            
          
        
          
            
              
                
                  and Petriu, Emil M.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In 2015 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)</em>
      
      
        2015
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Humans sense of touch consists in a complexity of sensors and nervous\nsystem. The information inferred by this system enables the daily\ndexterous manipulation tasks. In biological systems, there is no\nconscious prioritization of sensors while performing tactile exploration\nand the selection of exploratory movements is driven by learning\ninstincts and data gathered by previous movements. The development of\nartificial systems tries to mimic such systems with engineered sensors\nand strategies for movement selection. This paper presents a data-driven\nanalysis to the problem of sensor selection in the contour following for\nshape discrimination task. This task consists of a 4-DOF robotic finger\nexploring a set of 7 synthetic shapes. The data collected from the\nmotors, inertial measurement unit, and magnetometer was analyzed\napplying principal component analysis and a multilayer perceptron neural\nnetwork. Results show the variation of classification rate depending on\nthe fingertip material and sensor considered. It is worth to observe\nthat the magnetometer was the most robust in both cases.</p>
    </span>
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2023 Vinicius Prado da Fonseca.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
    Last updated: February 22, 2023.
    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.0/umd/popper.min.js" integrity="sha256-OH05DFHUWzr725HmuHo3pnuvUUn+TJuj8/Qz9xytFEw=" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/js/mdb.min.js"  integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/~vpradodafons/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" integrity="sha256-V8SV2MO1FUb63Bwht5Wx9x6PVHNa02gv8BgH/uH3ung=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js" integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc=" crossorigin="anonymous"></script>
<script src="/~vpradodafons/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>







</html>
