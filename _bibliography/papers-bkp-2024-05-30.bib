@article{DEOLIVEIRA2023e00478,
title = {BioIn-Tacto: A compliant multi-modal tactile sensing module for robotic tasks},
journal = {HardwareX},
pages = {e00478},
year = {2023},
issn = {2468-0672},
doi = {https://doi.org/10.1016/j.ohx.2023.e00478},
url = {https://www.sciencedirect.com/science/article/pii/S2468067223000858},
author = {Thiago Eustaquio Alves {de Oliveira} and Vinicius Prado {da Fonseca}},
keywords = {Tactile sensing, Compliant sensing module, Multimodal bio-inspired sensing, Touch perception, Data fusion, Haptics, Robot interaction},
}

@article{LIMA2023109590,
title = {A multimodal tactile dataset for dynamic texture classification},
journal = {Data in Brief},
pages = {109590},
year = {2023},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2023.109590},
url = {https://www.sciencedirect.com/science/article/pii/S2352340923006832},
author = {Bruno Monteiro Rocha Lima and Venkata Naga Sai Siddhartha Danyamraju and Thiago Eustaquio Alves {de Oliveira} and Vinicius Prado {da Fonseca}},
keywords = {Texture classification, Dynamic exploration, Tactile sensor, Machine learning}
}

@article{galaiya2023exploring,
  title={Exploring Tactile Temporal Features for Object Pose Estimation during Robotic Manipulation},
  author={Galaiya, Viral Rasik and Asfour, Mohammed and Alves de Oliveira, Thiago Eustaquio and Jiang, Xianta and Prado da Fonseca, Vinicius},
  journal={Sensors},
  volume={23},
  number={9},
  pages={4535},
  year={2023},
  publisher={MDPI}
}

@inproceedings{Haranwala2022,
abstract = {Mobility data mining has received significant interest in the literature in the last few years since social media, sensor networks, IoT, and GPS devices generate a vast amount of data. Its growth was also boosted by the growing availability of machine learning algorithms and Python libraries for trajectory analysis. However, we believe that a proper tool that supports trajectory data preprocessing tasks using a dashboard-like application is missing. Such a tool helps users visualize the effects of preprocessing techniques and adequately select the ones that have a desired effect on the data. This demo proposes a tool that combines state-of-the-art Python trajectory analysis libraries to preprocess trajectory data and visualize their effect using a dashboard with maps, tables, and charts that will assist the user through this challenging process.},
author = {Haranwala, Yaksh J. and Haidri, Salman and Tricco, Terrence S. and da Fonseca, Vinicius P. and Soares, Amilcar},
booktitle = {2022 23rd IEEE International Conference on Mobile Data Management (MDM)},
doi = {10.1109/MDM55031.2022.00059},
file = {::},
isbn = {978-1-6654-5176-5},
issn = {15516245},
month = {jun},
number = {Mdm},
pages = {278--281},
publisher = {IEEE},
title = {{A Dashboard Tool for Mobility Data Mining Preprocessing Tasks}},
url = {https://ieeexplore.ieee.org/document/9861122/},
year = {2022}
}
@article{Oliveira2022,
author = {de Oliveira, Thiago Eustaquio Alves and da Fonseca, Vinicius Prado},
doi = {10.5281/zenodo.7011242},
keywords = {robotics,sensors,tactile sensing},
month = {aug},
title = {{BioIn-Tacto: tactile sensing module design files and source code.}},
url = {https://doi.org/10.5281/zenodo.7011242#.YzyCBBMcay8.mendeley},
year = {2022}
}
@article{Wang2022,
abstract = {The myoelectric prosthesis is a promising tool to restore the hand abilities of amputees, but the classification accuracy of surface electromyography (sEMG) is not high enough for real-time application. Researchers proposed integrating sEMG signals with another feature that is not affected by amputation. The strong coordination between vision and hand manipulation makes us consider including visual information in prosthetic hand control. In this study, we identified a sweet period during the early reaching phase in which the vision data could yield a higher accuracy in classifying the grasp patterns. Moreover, the visual classification results from the sweet period could be naturally integrated with sEMG data collected during the grasp phase. After the integration, the accuracy of grasp classification increased from 85.5% (only sEMG) to 90.06% (integrated). Knowledge gained from this study encourages us to further explore the methods for incorporating computer vision into myoelectric data to enhance the movement control of prosthetic hands.},
author = {Wang, Shuo and Zheng, Jingjing and Huang, Ziwei and Zhang, Xiaoqin and {Prado da Fonseca}, Vinicius and Zheng, Bin and Jiang, Xianta},
doi = {10.3389/frobt.2022.948238},
issn = {2296-9144},
journal = {Frontiers in Robotics and AI},
month = {sep},
number = {September},
pages = {1--10},
title = {{Integrating computer vision to prosthetic hand control with sEMG: Preliminary results in grasp classification}},
url = {https://www.frontiersin.org/articles/10.3389/frobt.2022.948238/full},
volume = {9},
year = {2022}
}
@article{Haidri2022,
author = {Haidri, Salman and Haranwala, Yaksh J. and Bogorny, Vania and Renso, Chiara and da Fonseca, Vinicius Prado and Soares, Amilcar},
doi = {10.1016/j.softx.2022.101176},
file = {::},
issn = {23527110},
journal = {SoftwareX},
month = {jul},
pages = {101176},
title = {{PTRAIL — A python package for parallel trajectory data preprocessing}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2352711022001066},
volume = {19},
year = {2022}
}
@inproceedings{RochaLima2021,
abstract = {Reproducing human-like dexterous manipulation in robots requires identifying objects and ures. In unstructured settings, robots equipped with tactile sensors can detect ures by using touch-related characteristics. The use of a tactile-enabled finger for ure categorization is investigated in this article. Four machine learning methods are used to recognize ures from the data of pressure, gravity, angular rate, magnetic field sensors embedded in the compliant structure of a multimodal tactile sensing module. Machine learning models trained on data retrieved during 2-dimensional exploration of sample ures achieved classification accuracy rates of more than 90% for all features.},
author = {{Rocha Lima}, Bruno Monteiro and {Alves de Oliveira}, Thiago Eustaquio and da Fonseca, Vinicius Prado},
booktitle = {2021 IEEE Sensors},
doi = {10.1109/SENSORS47087.2021.9639755},
file = {::},
isbn = {978-1-7281-9501-8},
issn = {21689229},
keywords = {dynamic exploration,machine learning,tactile sensor,ure classification},
month = {oct},
pages = {1--4},
publisher = {IEEE},
title = {{Classification of Textures using a Tactile-Enabled Finger in Dynamic Exploration Tasks}},
url = {https://ieeexplore.ieee.org/document/9639755/},
volume = {2021-Octob},
year = {2021}
}
@article{DaFonseca2022,
author = {da Fonseca, Vinicius Prado and Jiang, Xianta and Petriu, Emil M and de Oliveira, Thiago Eustaquio Alves},
doi = {10.1007/s11370-022-00433-7},
file = {::},
issn = {1861-2776},
journal = {Intelligent Service Robotics},
keywords = {Applied machine learning,Object recognition,Tactile sensing and perception,Underactuated robot hands,applied machine learning,object recognition,tactile sensing and perception,underactuated robot hands},
month = {jul},
publisher = {Springer Berlin Heidelberg},
title = {{Tactile object recognition in early phases of grasping using underactuated robotic hands}},
url = {https://doi.org/10.1007/s11370-022-00433-7 https://link.springer.com/10.1007/s11370-022-00433-7},
year = {2022}
}
@inproceedings{Boente2021,
author = {Boente, Alexandre and Baldivieso, Thiago and Oliveira, Thiago and Fonseca, Vinicius and Rosa, Paulo},
booktitle = {SENSORDEVICES 2021, The Twelfth International Conference on Sensor Device Technologies and Applications},
isbn = {9781612089188},
keywords = {3D Reconstruction,Heritage Preservation,Photogrammetry,UAS},
number = {c},
pages = {7--12},
title = {{Small Scale Unmanned Aircraft System and Photogrammetry Applied for 3D Modeling of Historical Buildings}},
url = {https://www.thinkmind.org/index.php?view=article&articleid=sensordevices_2021_1_20_28016},
year = {2021}
}
@inproceedings{Carvalho2022,
author = {Carvalho, Humberto Navarro De and Castro, Lucas Pontes and Rego, Thais G. Do and Filho, Telmo M. Silva and Barbosa, Yuri de A. M. and Batista, Leonardo Vidal and Soares, Amilcar and Fonseca, Vinicius Prado Da},
booktitle = {2022 IEEE International Systems Conference (SysCon)},
doi = {10.1109/SysCon53536.2022.9773911},
file = {::},
isbn = {978-1-6654-3992-3},
month = {apr},
pages = {1--6},
publisher = {IEEE},
title = {{Evaluating Data Representations for Object Recognition During Pick-and-Place Manipulation Tasks}},
url = {https://ieeexplore.ieee.org/document/9773911/},
year = {2022}
}
@inproceedings{Welyhorsky2022,
author = {Welyhorsky, Maxwell and {Prado Da Fonseca}, Vinicius and Zhu, Qi and {Rocha Lima}, Bruno Monteiro and {Alves De Oliveira}, Thiago Eustaquio and Petriu, Emil M},
booktitle = {2022 IEEE International Systems Conference (SysCon)},
doi = {10.1109/SysCon53536.2022.9773821},
file = {::},
isbn = {978-1-6654-3992-3},
month = {apr},
pages = {1--5},
publisher = {IEEE},
title = {{Neuro-Fuzzy Grasp Control for a Teleoperated Five Finger Anthropomorphic Robotic Hand}},
url = {https://ieeexplore.ieee.org/document/9773821/},
year = {2022}
}
@article{Pirozzi2020,
abstract = {In recent years, tactile sensing has become a key enabling technology to implement complex tasks by using robotic systems [...]},
author = {Pirozzi, Salvatore},
doi = {10.3390/s20247009},
file = {::},
isbn = {9783036504247},
issn = {1424-8220},
journal = {Sensors},
mendeley-groups = {tactile},
month = {dec},
number = {24},
pages = {7009},
pmid = {33302388},
title = {{Tactile Sensors for Robotic Applications}},
url = {https://www.mdpi.com/1424-8220/20/24/7009},
volume = {20},
year = {2020}
}
@article{PradodaFonseca2021,
abstract = {Dexterous robotic manipulation in unstructured environments is still challenging, despite the increasing number of robots entering human settings each day. Even though robotic manipulation provides complete solutions in factories and industries, it still lacks essential techniques, displaying clumsy or limited operation in unstructured environments. Daily objects typically aim at the human hand, and the human somatosensory system is responsible for solving all the complex calculations required for dexterous manipulations in unstructured settings. Borrowing concepts of the human visuotactile system can improve dexterous manipulation and increase robotics usage in unstructured environments. In humans, required finger and wrist joint adjustments occur after fast identification of the object in the initial stages of manipulation. Fast object identification during those phases may increase robotic dexterous manipulation performance. The present paper explores human-inspired concepts such as haptic glance to develop robotic single-grasp object identification. This concept can assist early phases of robotic manipulation, helping automated decision-making, such as type of grasp and joint position, during manipulation tasks. The main stages developed here are detecting sensor activation and sample collection using signal-to-noise and z-score filtering on tactile data. This procedure automates touch detection and reduces the sensor space for classification. Experiments on a daily objects dataset presented compelling results that will assist in the later stages of the early phases of robotic grasping.},
author = {{Prado da Fonseca}, Vinicius},
doi = {10.3390/I3S2021Dresden-10091},
file = {::},
issn = {2673-4591},
journal = {Engineering Proceedings},
keywords = {object identification,robotic manipulation,tactile sensor},
month = {may},
number = {1},
pages = {56},
title = {{Tactile Sensor Analysis during Early Stages of Manipulation for Single Grasp Identification of Daily Objects}},
url = {https://www.mdpi.com/2673-4591/6/1/56},
volume = {6},
year = {2021}
}
@inproceedings{Monteiro2020,
author = {Lima, Bruno Monteiro Rocha and da Fonseca, Vinicius Prado and de Oliveira, Thiago Eustaquio Alves and Zhu, Qi and Petriu, Emil M.},
booktitle = {2020 IEEE International Systems Conference (SysCon)},
doi = {10.1109/SysCon47679.2020.9275871},
file = {::},
isbn = {978-1-7281-5365-0},
month = {aug},
pages = {1--7},
publisher = {IEEE},
title = {{Dynamic Tactile Exploration for Texture Classification using a Miniaturized Multi-modal Tactile Sensor and Machine Learning}},
url = {https://ieeexplore.ieee.org/document/9275871/},
year = {2020}
}
@inproceedings{Zhu2020,
author = {Zhu, Qi and da Fonseca, Vinicius Prado and Lima, Bruno Monteiro Rocha and Welyhorsky, Maxwell and Goubran, Miriam and de Oliveira, Thiago Eustaquio Alves and Petriu, Emil M},
booktitle = {2020 IEEE International Systems Conference (SysCon)},
doi = {10.1109/SysCon47679.2020.9275927},
file = {::},
isbn = {978-1-7281-5365-0},
month = {aug},
pages = {1--7},
publisher = {IEEE},
title = {{Teleoperated Grasping Using a Robotic Hand and a Haptic-Feedback Data Glove}},
url = {https://ieeexplore.ieee.org/document/9275927/},
year = {2020}
}
@article{PradodaFonseca2015,
author = {{Prado da Fonseca}, Vinicius and Rosa, Paulo Fernando Ferreira},
file = {::},
journal = {Revista Militar de Ci{\^{e}}ncia e Tecnologia},
number = {4},
pages = {5--14},
title = {{Protocolo de comunica{\c{c}}{\~{a}}o para localiza{\c{c}}{\~{a}}o de objetos na casa inteligente}},
volume = {XXXII},
year = {2015}
}
@article{Zhi2018,
abstract = {This paper presents a novel vision-based hand gesture recognition (HGR) and training system for a human-like robot hand. We implemented and trained a multiclass-SVM classifier and N-Dimensional DTW (ND-DTW) classifier for static posture recognition and dynamic gesture recognition. Training features were extracted from the raw gestures depth data captured by Leap Motion Controller. The experimental results show that multiclass SVM method has an average 98.25% recognition rates and the shortest run time when compared to k-NN and ANBC. For dynamic gestures, ND-DTW classifier displays a better performance than DHMM with an average 95.5% recognition rate and significantly shorter run time. In conclusion, the combination of SVMs and DTW proves the efficiency and high accuracy in proposed human-robot interaction system.},
author = {Zhi, Da and {De Oliveira}, Thiago E.Alves and {Da Fonseca}, Vinicius Prado and Petriu, Emil M.},
doi = {10.1109/CIVEMSA.2018.8439952},
file = {::},
isbn = {9781538646182},
journal = {CIVEMSA 2018 - 2018 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications, Proceedings},
keywords = {DTW,Hand gesture recognition,Leap Motion,Robotics,SVMs},
pages = {1--6},
publisher = {IEEE},
title = {{Teaching a robot sign language using vision-based hand gesture recognition}},
volume = {3528725544},
year = {2018}
}
@inproceedings{RochaLima2019,
author = {{Rocha Lima}, Bruno Monteiro and {Eustaquio Alves de Oliveira}, Thiago and da Fonseca, Vinicius Prado and Zhu, Qi and Goubran, Miriam and Groza, Voicu Z. and Petriu, Emil M.},
booktitle = {2019 IEEE International Symposium on Medical Measurements and Applications (MeMeA)},
doi = {10.1109/MeMeA.2019.8802209},
file = {::},
isbn = {978-1-5386-8428-3},
month = {jun},
pages = {1--6},
publisher = {IEEE},
title = {{Heart Rate Detection Using a Miniaturized Multimodal Tactile Sensor}},
url = {https://ieeexplore.ieee.org/document/8802209/},
year = {2019}
}
@inproceedings{AlvesdeOliveira2019,
abstract = {The flexibilization of the end-effector orientation constraint is critical in various robotic tasks, in particular when approaching surfaces of unknown objects and when unexpected contacts occur. This paper presents the use of a bioinspired multimodal tactile sensing module for tasks requiring knowledge about the inclination of a surface. The advantage of this module is that it can detect the pitch of the surface even though the pitch of the end-effector that carries the module during exploration is kept constant. Such flexibilization is achieved due to the compliant nature of the sensing module, its inner organization and the placement of embedded sensors.},
author = {{Alves de Oliveira}, Thiago Eustaquio and da Fonseca, Vinicius Prado and Lima, Bruno Monteiro Rocha and Cretu, Ana-Maria and Petriu, M.},
booktitle = {2019 IEEE International Symposium on Robotic and Sensors Environments (ROSE)},
doi = {10.1109/ROSE.2019.8790433},
file = {::},
isbn = {978-1-7281-1964-9},
keywords = {MARG,compliant structure,multimodal sensing,pressure sensor,surface inclination,tactile sensing},
month = {jun},
pages = {1--6},
publisher = {IEEE},
title = {{End-Effector Approach Flexibilization in a Surface Approximation Task Using a Bioinspired Tactile Sensing Module}},
url = {https://ieeexplore.ieee.org/document/8790433/},
year = {2019}
}
@inproceedings{DaFonseca2019-MeMeA,
abstract = {"Part Number: CFP19MEA-ART" "IEEE Catalog Number: CFP19MEA-USB"--PDF copyright page},
author = {da Fonseca, Vinicius Prado and {Monteiro Rocha Lima}, Bruno and {Alves de Oliveira}, Thiago Eustaquio and Zhu, Qi and Groza, Voicu Z. and Petriu, Emil M.},
booktitle = {2019 IEEE International Symposium on Medical Measurements and Applications (MeMeA)},
doi = {10.1109/MeMeA.2019.8802139},
file = {::},
isbn = {978-1-5386-8428-3},
keywords = {adapt robot hands to,control,fuzzy,in-hand manipulation,instead of having to,of the finger in,place the contact part,robotic hands,shapes of objects,strategy applied was to,tactile sensing},
month = {jun},
pages = {1--6},
publisher = {IEEE},
title = {{In-Hand Telemanipulation Using a Robotic Hand and Biology-Inspired Haptic Sensing}},
url = {https://ieeexplore.ieee.org/document/8802139/},
year = {2019}
}
@article{Kucherhan2018,
author = {Kucherhan, Daniel J. and Goubran, Miriam and {Da Fonseca}, Vinicius P. and {Alves De Oliveira}, Thiago E. and Petriu, Emil M. and Groza, Voicu},
doi = {10.1109/MeMeA.2018.8438757},
file = {::},
isbn = {9781538633915},
journal = {MeMeA 2018 - 2018 IEEE International Symposium on Medical Measurements and Applications, Proceedings},
keywords = {in-hand manipulation,object recognition,prosthetic finger,tactile feedback,tactile sensors},
pages = {1--6},
publisher = {IEEE},
title = {{Object Recognition Through Manipulation Using Tactile Enabled Prosthetic Fingers and Feedback Glove - Experimental Study}},
year = {2018}
}
@article{DeOliveira2015-mag,
abstract = {A new generation of humanoid robots is emerging to work together with, or even replace, human operators performing complex dextrous manipulation operations in a variety of applications such as health and elder care, hazardous or high-risk environments, telemedicine, or manufacturing. To meet the challenging operational requirements of such applications, this new generation of humanoid robots should not only look as humans, but should also behave like them, being able to sense and perceive the external world and perform tasks as humans do. Touch sensing and perception is essential when handling objects while working on such complex activities in unstructured environments. The major challenges encountered when replicating the human touch sensing mechanisms are due to the inherently low resolution of the tactile images produced by the artificial sensors, to the complexity of interpreting the sensor data, and to the fact that robot hand technology is still clumsy when compared with the nimble dexterity of the human hand and fingers. This paper presents practical touch sensing solutions for humanoid robots (Fig. 1) that mimic the complex sensing mechanisms occurring in a human hand while exploring by touch 3D objects.},
author = {de Oliveira, Thiago Eustaquio Alves and Cretu, Ana-Maria and da Fonseca, Vinicius Prado and Petriu, Emil M.},
doi = {10.1109/MIM.2015.7271221},
file = {::},
issn = {1094-6969},
journal = {IEEE Instrumentation & Measurement Magazine},
month = {oct},
number = {5},
pages = {13--19},
title = {{Touch sensing for humanoid robots}},
url = {http://ieeexplore.ieee.org/document/7271221/},
volume = {18},
year = {2015}
}
@article{PradodaFonseca2019,
abstract = {Underactuated hands are useful tools for robotic in-hand manipulation tasks due to their capability to seamlessly adapt to unknown objects. To enable robots using such hands to achieve and maintain stable grasping conditions even under external disturbances while keeping track of an in-hand object's state requires learning object-tactile sensing data relationships. The human somatosensory system combines visual and tactile sensing information in their “What and Where” subsystem to achieve high levels of manipulation skills. The present paper proposes an approach for estimating the pose of in-hand objects combining tactile sensing data and visual frames of reference like the human “What and Where” subsystem. The system proposed here uses machine learning methods to estimate the orientation of in-hand objects from the data gathered by tactile sensors mounted on the phalanges of underactuated fingers. While tactile sensing provides local information about objects during in-hand manipulation, a vision system generates egocentric and allocentric frames of reference. A dual fuzzy logic controller was developed to achieve and sustain stable grasping conditions autonomously while forces were applied to in-hand objects to expose the system to different object configurations. Two sets of experiments were used to explore the system capabilities. On the first set, external forces changed the orientation of objects while the fuzzy controller kept objects in-hand for tactile and visual data collection for five machine learning estimators. Among these estimators, the ridge regressor achieved an average mean squared error of 0.077 ∘ . On the second set of experiments, one of the underactuated fingers performed open-loop object rotations and data recorded were supplied to the same set of estimators. In this scenario, the Multilayer perceptron (MLP) neural network achieved the lowest mean squared error of 0.067 ∘ .},
author = {{Prado da Fonseca}, Vinicius and {Alves de Oliveira}, Thiago Eustaquio and Petriu, Emil M.},
doi = {10.3390/s19102285},
file = {::},
issn = {1424-8220},
journal = {Sensors},
keywords = {fuzzy control,in-hand manipulation,machine learning,pose estimation,underactuated},
month = {may},
number = {10},
pages = {2285},
title = {{Estimating the Orientation of Objects from Tactile Sensing Data Using Machine Learning Methods and Visual Frames of Reference}},
url = {https://www.mdpi.com/1424-8220/19/10/2285},
volume = {19},
year = {2019}
}
@inproceedings{Cretu2015,
abstract = {The paper discusses signal processing and mechatronics solutions for tactile object recognition using robotic hands. The two important aspects analyzed are the recognition of objects from tactile displacement profiles obtained by force sensing transducers and the recognition of textures using a rubbing motion executed by a robotic finger equipped with a dynamic tactile fingertip. Neural network solutions are used as an intelligent approach to recognize symbols, such as embossed numbers and letters, as well as for the recognition of different texture profiles. The conception issues, the challenges as well as the experimental results obtained are discussed from both a biological and a technological perspective.},
author = {Cretu, Ana-Maria and de Oliveira, Thiago Eustaquio Alves and {Prado da Fonseca}, Vinicius and Tawbe, Bilal and Petriu, Emil M. and Groza, Voicu Z.},
booktitle = {2015 IEEE 9th International Symposium on Intelligent Signal Processing (WISP) Proceedings},
doi = {10.1109/WISP.2015.7139165},
file = {::},
isbn = {978-1-4799-7253-1},
keywords = {haptic perception,image processing,mechatronics,model-based recognition,neural networks,principal component analysis,robot hand,tactile sensor},
month = {may},
pages = {1--6},
publisher = {IEEE},
title = {{Computational intelligence and mechatronics solutions for robotic tactile object recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7139165 http://ieeexplore.ieee.org/document/7139165/},
year = {2015}
}
@inproceedings{DaFonseca2017-nao,
abstract = {{\textcopyright} 2017 IEEE. Use of underactuated fingers to conduct precision, in-hand manipulation is a common topic of recent robotics research, mostly due to their relatively light weight and simplicity of use. Grasping operations are facilitated by compliant joints however precise, in-hand manipulation is more challenging since post-grasp orientation of an object varies. Underactuated, robotic-fingered hands that are capable of predictable grasping are one step closer to human-like end-effectors. This paper presents a new effort towards effective robotic manipulation using two underactuated fingers and one fully actuated robotic thumb with 3 degrees of freedom (DOF). Fuzzy grasping using tactile feedback is used to provide an enhanced stable grasp solution. The system comprises tactile feedback, orientation of underactuated phalanges using flexible joints, and thumb trajectory planning.},
author = {da Fonseca, Vinicius Prado and Kucherhan, Daniel John and de Oliveira, Thiago E. Alves and Zhi, Da and Petriu, Emil M.},
booktitle = {2017 Annual IEEE International Systems Conference (SysCon)},
doi = {10.1109/SYSCON.2017.7934753},
file = {::},
isbn = {978-1-5090-4623-2},
keywords = {fuzzy control,tactile feedback,underactuated fingers},
month = {apr},
pages = {1--6},
publisher = {IEEE},
title = {{Fuzzy controlled object manipulation using a three-fingered robotic hand}},
url = {http://ieeexplore.ieee.org/document/7934753/},
year = {2017}
}
@article{Kucherhan2018,
author = {Kucherhan, Daniel J. and Goubran, Miriam and {Da Fonseca}, Vinicius P. and {Alves De Oliveira}, Thiago E. and Petriu, Emil M. and Groza, Voicu},
doi = {10.1109/MeMeA.2018.8438757},
file = {::},
isbn = {9781538633915},
journal = {MeMeA 2018 - 2018 IEEE International Symposium on Medical Measurements and Applications, Proceedings},
keywords = {in-hand manipulation,object recognition,prosthetic finger,tactile feedback,tactile sensors},
pages = {1--6},
publisher = {IEEE},
title = {{Object Recognition Through Manipulation Using Tactile Enabled Prosthetic Fingers and Feedback Glove - Experimental Study}},
volume = {3528725544},
year = {2018}
}
@inproceedings{PradoDaFonseca2017-IRIS,
author = {{Prado da Fonseca}, Vinicius and de Oliveira, Thiago E. Alves and Eyre, Katerina and Petriu, Emil M.},
booktitle = {2017 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS)},
doi = {10.1109/IRIS.2017.8250140},
file = {::},
isbn = {978-1-5386-1342-9},
keywords = {fuzzy control,tactile feedback,under-actuated fingers},
month = {oct},
pages = {311--317},
publisher = {IEEE},
title = {{Stable grasping and object reorientation with a three-fingered robotic hand}},
url = {http://ieeexplore.ieee.org/document/8250140/},
volume = {2018-Janua},
year = {2017}
}
@inproceedings{DaFonseca2013,
abstract = {A RSSI-based localization system on a home wireless sensor network is proposed in this work. In order to support a robot assistant in pick-and-place tasks, our current system is capable of estimating the localization of an object using the signal strength received by a mobile device in a ZigBee sensor network. Two models were utilized (a) log-distance path loss - model in which signal lost has a random influence with log-normal distribution, and (b) free space decay law - based on the decay law for a signal on an open space. RSSI measurements were done in laboratory for applying the estimation method. Moreover experiments with satisfactory results were done with a public dataset to benchmark our results.},
author = {{Da Fonseca}, Vinicius Prado and Rosa, Paulo F.F.},
booktitle = {Proceedings - 1st BRICS Countries Congress on Computational Intelligence, BRICS-CCI 2013},
doi = {10.1109/BRICS-CCI-CBIC.2013.101},
file = {::},
isbn = {9781479931941},
keywords = {Indoors Location System,RSSI,ZigB},
pages = {574--579},
title = {{Tracking objects in a smart home}},
year = {2013}
}
@inproceedings{DaFonseca2013a,
abstract = {This article presents a system for tracking the position of objects within a smart home to support a robot assistant in pick-and-place tasks. The current system is capable of estimating the position of an object using the signal strength received by a mobile device in a ZigBee sensor network. Received strength signal indication measurements were done in laboratory for applying a estimation method. Two models were utilized (a) log-distance path loss - model in which signal lost has a random influence with log-normal distribution, and (b) free space decay law - based on the decay law for a signal on a open space. Experiments with satisfactory results were done with a public dataset to benchmark our data.},
author = {da Fonseca, Vinicius Prado and Rosa, Paulo F. F.},
booktitle = {IECON 2013 - 39th Annual Conference of the IEEE Industrial Electronics Society},
doi = {10.1109/IECON.2013.6700031},
file = {::},
isbn = {978-1-4799-0224-8},
keywords = {Indoors Positioning System,RSSI,ZigBee},
month = {nov},
pages = {5492--5497},
publisher = {IEEE},
title = {{Indoors object location protocol in a smart home}},
url = {http://ieeexplore.ieee.org/document/6700031/},
year = {2013}
}
@inproceedings{DeOliveira2015,
abstract = {Humans sense of touch consists in a complexity of sensors and nervous\nsystem. The information inferred by this system enables the daily\ndexterous manipulation tasks. In biological systems, there is no\nconscious prioritization of sensors while performing tactile exploration\nand the selection of exploratory movements is driven by learning\ninstincts and data gathered by previous movements. The development of\nartificial systems tries to mimic such systems with engineered sensors\nand strategies for movement selection. This paper presents a data-driven\nanalysis to the problem of sensor selection in the contour following for\nshape discrimination task. This task consists of a 4-DOF robotic finger\nexploring a set of 7 synthetic shapes. The data collected from the\nmotors, inertial measurement unit, and magnetometer was analyzed\napplying principal component analysis and a multilayer perceptron neural\nnetwork. Results show the variation of classification rate depending on\nthe fingertip material and sensor considered. It is worth to observe\nthat the magnetometer was the most robust in both cases.},
author = {{Eustaquio Alves de Oliveira}, Thiago and {Prado da Fonseca}, Vinicius and Huluta, Emanuil and Rosa, Paulo F F and Petriu, Emil M.},
booktitle = {2015 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)},
doi = {10.1109/CIVEMSA.2015.7158615},
file = {::},
isbn = {978-1-4799-6092-7},
month = {jun},
pages = {1--5},
publisher = {IEEE},
title = {{Data-driven analysis of kinaesthetic and tactile information for shape classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7158615 https://ieeexplore.ieee.org/document/7158615/},
year = {2015}
}
